{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8274944,"sourceType":"datasetVersion","datasetId":4913605}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LAB 2: Recommender System from Scratch","metadata":{"id":"yVlwEEkWlXEu"}},{"cell_type":"markdown","source":"Giorgio Lazzarinetti - My Contacts\nFor any questions or doubts you can find my contacts here:\n\ngiorgiolazzarinetti@gmail.com g.lazzarinetti@campus.unimib.it","metadata":{"id":"aUSaHRazlauW"}},{"cell_type":"markdown","source":"## Notebook Outline\n\n- **Introduction to Recommender System**\n- **Movielens Dataset**\n- **Generalized Matrix Factorization Model**\n- **Neural Collaborative Filtering**\n- **LAB CHALLENGE 1: Neural Matrix Factorization**","metadata":{"id":"Kg__F8YqsqGq"}},{"cell_type":"markdown","source":"## References\n\nThe architecture of the deep model, the evaluation strategy and the metrics used are taken from the paper: [\"Neural Collaborative Filtering\"](https://arxiv.org/abs/1708.05031) by He Xiangnan, Liao Lizi, Zhang Hanwang, Nie Liqiang, Hu Xia and Chua Tat-Seng - In Porc. of the 26th Interantional Conference on World Wide Web - 2017.","metadata":{"id":"ZxysEMZCO5sp"}},{"cell_type":"markdown","source":"## Introduction to Recommender System\n\nRecommender systems are algorithms that mimic the psychology and personality of humans, in order to predict their needs and desires. More formally, recommender systems adopt data-mining and machine-learning techniques to help users in finding attractive and useful products. Products can be almost anything: physical items (e.g., smartphones), places (e.g., restaurants), digital content (e.g., movies and music), and many more. Recommender systems produce recommendations based on different inputs: demographic information about users, ratings and comments on products, individual’s or community’s past preferences and choices, social networks, context of use.\n\nThere are many different types of techniques and implementations out there.\n\n- **Content-based methods** uses attributes of items to recommend to users new items similar to what the user has liked in the past (doesn't take into account the behaviour of other users);\n- **Collaborative Filtering methods** uses similarities between users and items simultaneously to determine recommendations;\n- **Hybrid methos** mix content-based and collaborative filtering approaches.\n\nOther approaches are also called **Knowlege-based methods** which uses explicit knowledge about users and items to build recommendations criteria with a rule-based approach.\n\n\n<center>  <img src=\"https://drive.google.com/uc?export=view&id=1Qaizz9YLvqgXg0blWFwN92IQSQPLTSoH\" width=\"950\" height=\"400\"> </center>\n\n\nIn the following we'll focus on Collaborative Filtering methods, with a model-based approach with deep learning algorithms.\n\n### Problem Definition\n\nGiven a past record of movies seen by a user, we will build a recommender system that helps the user discover movies of their interest.\n\nSpecifically, given <userID, itemID> occurrence pairs, we need to generate a ranked list of movies for each user.\n\nWe model the problem as a binary classification problem, where we learn a function to predict whether a particular user will like a particular movie or not.\n\n$$f(userid, itemid) →, [0,1]$$\n\nThe model takes in two sparse vectors, one representing the user and the other represents items. The users vector has size #users, while the items vector has size #items.  \n\nSo, elaborately,\n- User vector=[0,0,1...,0,0,0] with m elements, means this vector represents the 3 rd user out of m.\n- Item vector=[0,1,0,0,0,0...0] with n elements, means this vector represents the 2 nd item out of n.\n\nBasically both items and users are one-hot encoded.\n\nThese two vectors should be passed to a first embedding layer  (to project sparse representations to dense ones). These embeddings can be seen as a latent vector for users and items.\n\nThus, the final predictive model will be\n$$y_{ui} = f(\\mathbf{P}^T\\mathbf{v}_u^T, \\mathbf{Q}^T\\mathbf{v}_i^T | \\mathbf{P}, \\mathbf{Q}, \\mathbf{\\Theta}_f) $$\n\nwhere **P** and **Q** denotes the latent factor matrix for users and items and **$\\Theta_f$** denotes the model parameters.\n","metadata":{"id":"vwK9BJ1bss0_"}},{"cell_type":"markdown","source":"### Packages","metadata":{"id":"9131NU_plgbG"}},{"cell_type":"code","source":"import os\nimport time\nimport random\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"id":"Yji9-7jslKRz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(7)\ntorch.manual_seed(0)","metadata":{"id":"arJu3Re7XCky","outputId":"4fb13885-a709-4db6-9154-a0eef90763e5","execution":{"iopub.status.busy":"2024-05-02T14:53:26.354846Z","iopub.execute_input":"2024-05-02T14:53:26.355489Z","iopub.status.idle":"2024-05-02T14:53:26.362841Z","shell.execute_reply.started":"2024-05-02T14:53:26.355460Z","shell.execute_reply":"2024-05-02T14:53:26.361774Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7e9c95701d90>"},"metadata":{}}]},{"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\nprint(device)","metadata":{"id":"IkcVzJcY5TS_","execution":{"iopub.status.busy":"2024-05-02T14:53:29.362592Z","iopub.execute_input":"2024-05-02T14:53:29.363530Z","iopub.status.idle":"2024-05-02T14:53:29.368471Z","shell.execute_reply.started":"2024-05-02T14:53:29.363495Z","shell.execute_reply":"2024-05-02T14:53:29.367537Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"#/kaggle/input/u-data/u.data","metadata":{"execution":{"iopub.status.busy":"2024-05-02T08:38:09.358140Z","iopub.execute_input":"2024-05-02T08:38:09.358486Z","iopub.status.idle":"2024-05-02T08:38:09.363969Z","shell.execute_reply.started":"2024-05-02T08:38:09.358453Z","shell.execute_reply":"2024-05-02T08:38:09.363073Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Movielens Dataset\n\n### Dataset\n\nWe use the MovieLens 100K dataset, which has 100,000 ratings from 1000 users on 1700 movies.\n\nThe ratings are given to us in form of <userID,itemID, rating, timestamp> tuples. Each user has a minimum of 20 ratings.\n\nYou can download the dataset [here](https://grouplens.org/datasets/movielens/). Download the file ml-100k.zip. Unzip it and extract the file u.data\n\n### Create Dataset\n\nHere we are going to create the necessary dataset for building recommender system.\n\nAfter downloading the file as indicated, save them in your Colab Notebooks directory. In order to let the Notebook see the file on your Drive you have to mount it.","metadata":{"id":"epmWgmA5w920"}},{"cell_type":"code","source":"dataset_origin = {'100k': 'u.data', '1M': 'ratings.dat'}\n\nnum_sample_data = '100k'\nDATA_PATH = '/kaggle/input/u-data/{}'.format(dataset_origin[num_sample_data]) #change this with your directory\nMODEL_PATH = '/kaggle/input{}/'.format(num_sample_data) #change this with your directory\n","metadata":{"id":"qcffYFMdxDcI","execution":{"iopub.status.busy":"2024-05-02T14:53:34.912716Z","iopub.execute_input":"2024-05-02T14:53:34.913536Z","iopub.status.idle":"2024-05-02T14:53:34.918189Z","shell.execute_reply.started":"2024-05-02T14:53:34.913503Z","shell.execute_reply":"2024-05-02T14:53:34.917203Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"We now build some function to manage the data.\n\nWe drop the exact value of rating (1,2,3,4,5) and instead convert it to an implicit scenario i.e. any positive interaction is given value of 1. All other interactions are given a value of zero, by default.\n\nSince we are training a classifier, we need both positive and negative samples. The records present in the dataset are counted as positive samples. We assume that all entries in the user-item interaction matrix are negative samples (a strong assumption, and easy to implement).\n\nWe randomly sample 4 items that are not interacted by the user, for every item interacted by the user. This way, if a user has 20 positive interactions, he will have 80 negative interactions. These negative interactions cannot contain any positive interaction by the user, though they may not be all unique due to random sampling.","metadata":{"id":"kZ43K6UT9UmJ"}},{"cell_type":"markdown","source":"We now define the class MovieLens Dataset which will be used do read the data and create the train and test dataset.","metadata":{"id":"tE13kg0aydtu"}},{"cell_type":"code","source":"class Rating_Datset(Dataset):\n\tdef __init__(self, user_list, item_list, rating_list):\n\t\tsuper(Rating_Datset, self).__init__()\n\t\tself.user_list = user_list\n\t\tself.item_list = item_list\n\t\tself.rating_list = rating_list\n\n\tdef __len__(self):\n\t\treturn len(self.user_list)\n\n\tdef __getitem__(self, idx):\n\t\tuser = self.user_list[idx]\n\t\titem = self.item_list[idx]\n\t\trating = self.rating_list[idx]\n\n\t\treturn (\n\t\t\ttorch.tensor(user, dtype=torch.long),\n\t\t\ttorch.tensor(item, dtype=torch.long),\n\t\t\ttorch.tensor(rating, dtype=torch.float)\n\t\t\t)","metadata":{"id":"hmlijxEoYXDj","execution":{"iopub.status.busy":"2024-05-02T14:53:37.772458Z","iopub.execute_input":"2024-05-02T14:53:37.773104Z","iopub.status.idle":"2024-05-02T14:53:37.780428Z","shell.execute_reply.started":"2024-05-02T14:53:37.773073Z","shell.execute_reply":"2024-05-02T14:53:37.779316Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"class NCF_Data(object):\n\t\"\"\"\n\tConstruct Dataset for NCF\n\t\"\"\"\n\tdef __init__(self, args, ratings):\n\t\tself.ratings = ratings\n\t\tself.num_ng = args.num_ng\n\t\tself.num_ng_test = args.num_ng_test\n\t\tself.batch_size = args.batch_size\n\n\t\tself.preprocess_ratings = self._reindex(self.ratings)\n\n\t\tself.user_pool = set(self.ratings['user_id'].unique())\n\t\tself.item_pool = set(self.ratings['item_id'].unique())\n\n\t\tself.train_ratings, self.test_ratings = self._leave_one_out(self.preprocess_ratings)\n\t\tself.negatives = self._negative_sampling(self.preprocess_ratings)\n\n\n\tdef _reindex(self, ratings):\n\t\t\"\"\"\n\t\tProcess dataset to reindex userID and itemID, also set rating as binary feedback\n\t\t\"\"\"\n\t\tuser_list = list(ratings['user_id'].drop_duplicates())\n\t\tuser2id = {w: i for i, w in enumerate(user_list)}\n\n\t\titem_list = list(ratings['item_id'].drop_duplicates())\n\t\titem2id = {w: i for i, w in enumerate(item_list)}\n\n\t\tratings['user_id'] = ratings['user_id'].apply(lambda x: user2id[x])\n\t\tratings['item_id'] = ratings['item_id'].apply(lambda x: item2id[x])\n\t\tratings['rating'] = ratings['rating'].apply(lambda x: float(x > 0))\n\t\treturn ratings\n\n\tdef _leave_one_out(self, ratings):\n\t\t\"\"\"\n\t\tleave-one-out evaluation protocol in paper https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf\n\t\t\"\"\"\n\t\tratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=False)\n\t\ttest = ratings.loc[ratings['rank_latest'] == 1]\n\t\ttrain = ratings.loc[ratings['rank_latest'] > 1]\n\t\tassert train['user_id'].nunique()==test['user_id'].nunique(), 'Not Match Train User with Test User'\n\t\treturn train[['user_id', 'item_id', 'rating']], test[['user_id', 'item_id', 'rating']]\n\n\tdef _negative_sampling(self, ratings):\n\t\tinteract_status = (\n\t\t\tratings.groupby('user_id')['item_id']\n\t\t\t.apply(set)\n\t\t\t.reset_index()\n\t\t\t.rename(columns={'item_id': 'interacted_items'}))\n\t\tinteract_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self.item_pool - x)\n\t\tinteract_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n\t\treturn interact_status[['user_id', 'negative_items', 'negative_samples']]\n\n\tdef get_train_instance(self):\n\t\tusers, items, ratings = [], [], []\n\t\ttrain_ratings = pd.merge(self.train_ratings, self.negatives[['user_id', 'negative_items']], on='user_id')\n\t\ttrain_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n\t\tfor row in train_ratings.itertuples():\n\t\t\tusers.append(int(row.user_id))\n\t\t\titems.append(int(row.item_id))\n\t\t\tratings.append(float(row.rating))\n\t\t\tfor i in range(self.num_ng):\n\t\t\t\tusers.append(int(row.user_id))\n\t\t\t\titems.append(int(row.negatives[i]))\n\t\t\t\tratings.append(float(0))  # negative samples get 0 rating\n\t\tdataset = Rating_Datset(\n\t\t\tuser_list=users,\n\t\t\titem_list=items,\n\t\t\trating_list=ratings)\n\t\treturn DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n\tdef get_test_instance(self):\n\t\tusers, items, ratings = [], [], []\n\t\ttest_ratings = pd.merge(self.test_ratings, self.negatives[['user_id', 'negative_samples']], on='user_id')\n\t\tfor row in test_ratings.itertuples():\n\t\t\tusers.append(int(row.user_id))\n\t\t\titems.append(int(row.item_id))\n\t\t\tratings.append(float(row.rating))\n\t\t\tfor i in getattr(row, 'negative_samples'):\n\t\t\t\tusers.append(int(row.user_id))\n\t\t\t\titems.append(int(i))\n\t\t\t\tratings.append(float(0))\n\t\tdataset = Rating_Datset(\n\t\t\tuser_list=users,\n\t\t\titem_list=items,\n\t\t\trating_list=ratings)\n\t\treturn DataLoader(dataset, batch_size=self.num_ng_test+1, shuffle=False, num_workers=2)","metadata":{"id":"FxZCDy4tYkRZ","execution":{"iopub.status.busy":"2024-05-02T14:53:43.058212Z","iopub.execute_input":"2024-05-02T14:53:43.058578Z","iopub.status.idle":"2024-05-02T14:53:43.081461Z","shell.execute_reply.started":"2024-05-02T14:53:43.058549Z","shell.execute_reply":"2024-05-02T14:53:43.080549Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation Metrics\n\nWe randomly sample 100 items that are not interacted by the user, ranking the test item among the 100 items. We truncate the ranked list at 10.\n\nSince it is too time-consuming to rank all items for every user, for we will have to calculate 1000\\*1700 ~10⁶ values. With this strategy, we need 1000*100 ~ 10⁵ values, an order of magnitude less.\n\nFor each user, we use the latest rating(according to timestamp) in the test set, and we use the rest for training. This evaluation methodology is also known as leave-one-out strategy.\n\n#### Metrics\n\nWe use **Hit Ratio** (HR), and **Normalized Discounted Cumulative Gain** (NDCG) to evaluate the performance for our RS.\n\n\nIn recommender settings, the **HR** is simply the fraction of users for which the correct answer is included in the recommendation list of length L.\n\n$$HR = \\frac{|U_{hit}^{L}|}{U_{all}}$$\n\nWhere $U_{hit}^{L}$ is the number of users for which the correct answer is included in the top L recommendation list, while, $U_{all}$ is the total number of user in the test dataset. Clearly the larger L is the larger HR become.\n\n**NDCG** is a measure of ranking quality. In information retrieval, it is often used to measure effectiveness of web search engine algorithms or related applications. Using a graded relevance scale of documents in a search-engine result set, DCG measures the usefulness, or gain, of a document based on its position in the result list. The gain is accumulated from the top of the result list to the bottom, with the gain of each result discounted at lower ranks\n\n**Gain** for an item is essentialy the same as the relevance score, which can be numerical ratings like search results in Google which can be rated in scale from 1 to 5, or binary in case of implicit data where we only know if a user has consumed certain item or not. Naturally **Cumulative Gain** is defined as the sum of gains up to a position k in the recommendation list.\n\n$$CG(k) = \\sum_{i=1}^{k}G_i$$\n\nOne obvious drawback of CG is that it does not take into account of ordering. By swapping the relative order of any two items, the CG would be unaffected. This is problematic when ranking order is important. For example, on Google Search results, you would obviously not like placing the most relevant web page at the bottom.\n\nTo penalize highly relevant items being placed at the bottom, we introduce the **Discounted Cumulative Gaing** (DCG).\n\n$$DCG(k) = \\sum_{i=1}^{k} \\frac{G_i}{log_2(i+1)}$$\n\nBy diving the gain by its rank, we sort of push the algorithm to place highly relevant items to the top to achieve the best DCG score.\n\nThere is still a drawback of DCG score. It is that DCG score adds up with the length of recommendation list. Therefore, we cannot consistently compare the DCG score for system recommending top 5 and top 10 items, because the latter will have higher score not because its recommendation quality but pure length.\n\nWe tackle this issue by introducing **Ideal Discounted Cumulative Gain** (IDCG). IDCG is the DCG score for the most ideal ranking, which is ranking the items top down according their relevance up to position k.\n\n$$IDCG(k) = \\sum_{i=1}^{|I(k)|} \\frac{G_i}{log_2(i+1)}$$\n\nWhere $|I(k)|$ represent the ideal list of items up to position k.\n\nAnd NDCG is simply to normalize the DCG score by IDCG such that its value is always between 0 and 1 regardless of the length.\n\n$$NDCD(k) = \\frac{DCG(k)}{IDCG(k)}$$\n\nOur model gives a confidence score between 0 and 1 for each item present in the test set for a given user. The items are sorted in decreasing order of their score, and top 10 items are given as recommendation. If the test item (which is only one for each user) is present in this list, HR is one for this user, else it is zero. The final HR is reported after averaging for all users. A similar calculation is done for NDCG.\n\nWhile training, we will be minimizing the cross-entropy loss, which is the standard loss function for a classification problem. The real strength of RS lies in giving a ranked list of top-k items, which a user is most likely to interact. Think about why you mostly click on google search results only on the first page, and never go to other pages. Metrics like NDCG and HR help in capturing this phenomenon by indicating the quality of our ranked lists.","metadata":{"id":"qx2UpNblDKH0"}},{"cell_type":"code","source":"def hit(ng_item, pred_items):\n\tif ng_item in pred_items:\n\t\treturn 1\n\treturn 0\n\n\ndef ndcg(ng_item, pred_items):\n\tif ng_item in pred_items:\n\t\tindex = pred_items.index(ng_item)\n\t\treturn np.reciprocal(np.log2(index+2))\n\treturn 0\n\n\ndef metrics(model, test_loader, top_k, device):\n\tHR, NDCG = [], []\n\n\tfor user, item, label in test_loader:\n\t\tuser = user.to(device)\n\t\titem = item.to(device)\n\n\t\tpredictions = model(user, item)\n\t\t_, indices = torch.topk(predictions, top_k)\n\t\trecommends = torch.take(\n\t\t\t\titem, indices).cpu().numpy().tolist()\n\n\t\tng_item = item[0].item() # leave one-out evaluation has only one item per user\n\t\tHR.append(hit(ng_item, recommends))\n\t\tNDCG.append(ndcg(ng_item, recommends))\n\n\treturn np.mean(HR), np.mean(NDCG)","metadata":{"id":"uTaIX7H52i-a","execution":{"iopub.status.busy":"2024-05-02T14:53:47.051811Z","iopub.execute_input":"2024-05-02T14:53:47.052527Z","iopub.status.idle":"2024-05-02T14:53:47.060644Z","shell.execute_reply.started":"2024-05-02T14:53:47.052497Z","shell.execute_reply":"2024-05-02T14:53:47.059666Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## Generalized Matrix Factorization (GMF)\n\nGenerally Matrix Factorization (MF) algorithms associates each user and item with a real-valued vector of latent features.\n\nLet $\\mathbf{p_u}$ and $\\mathbf{q_i}$ denote the latent vector for user u and item i, respectively; MF estimates an interaction y_{ui} as the inner product of $\\mathbf{p_u}$ and $\\mathbf{q_i}$:\n\n$$y_{ui} = f(u, i| \\mathbf{p_u}, \\mathbf{q_i}) = \\mathbf{p_u}^T\\mathbf{q_i} = \\sum_{k=1}^Kp_{uk}q_{ik} $$\n\nWhere K denotes the dimension of the latent space.\n\nMF models the dimension of the interaction of user and item latent factors, assuming each dimension of the latent space is independent of each other and linearly combining them  with the same weights.\n\nThis imposes some limitation of MF caused by the use of a simple and fixed inner product to estimate complex user-item interactions in the low-dimensional latent space.\n\nIn order to overcome this limitation, we can build a Generalized Matrix Factorization (GMF) algorithm where we can weight the linear combination of the element-wise product and use this with an activation function to learn a representation of the input insted of using a fixed one.\n\nLet the user latent vector $\\mathbf{p_u}$  be denoted as $\\mathbf{P}^T\\mathbf{v}_u^T$ and the item latent vector $\\mathbf{q_i}$ as $\\mathbf{Q}^T\\mathbf{v}_i^T$.\n\nThe GMF can be expressed as\n$$Y_{ui} = a_{out}(\\mathbf{h}^T(\\mathbf{p_u}\\odot \\mathbf{q_i})$$\nwhere $a_{out}$ is the activation function and $\\mathbf{h}$ are the edge weights of the output layer.\n\nIntuitively, if we use an identity function as $a_{out}$ and enforce $\\mathbf{h}$ to be a uniform vector of 1, we can exactly recover the MF model.\n\nIn the following we will use $\\mathbf{h}$ as linear layer and a $a_{out}$ as sigmoid function to learn $\\mathbf{h}$ weigths from data with the log loss.\n\n","metadata":{"id":"KuigI6hAj6Fm"}},{"cell_type":"code","source":"class GMF(nn.Module):\n    def __init__(self, args, num_users, num_items):\n        super(GMF, self).__init__()\n        self.num_users = num_users\n        self.num_items = num_items\n        self.factor_num = args.factor_num\n\n        self.embedding_user = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num)\n        self.embedding_item = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num)\n\n        self.affine_output = nn.Linear(in_features=self.factor_num, out_features=1)\n        self.logistic = nn.Sigmoid()\n\n    def forward(self, user_indices, item_indices):\n        user_embedding = self.embedding_user(user_indices)\n        item_embedding = self.embedding_item(item_indices)\n        element_product = torch.mul(user_embedding, item_embedding)\n        logits = self.affine_output(element_product)\n        rating = self.logistic(logits)\n        return rating.squeeze()\n\n    def init_weight(self):\n        pass","metadata":{"id":"DTMHganmd5q1","execution":{"iopub.status.busy":"2024-05-02T20:20:29.349260Z","iopub.execute_input":"2024-05-02T20:20:29.350263Z","iopub.status.idle":"2024-05-02T20:20:29.361854Z","shell.execute_reply.started":"2024-05-02T20:20:29.350209Z","shell.execute_reply":"2024-05-02T20:20:29.360586Z"},"trusted":true},"execution_count":390,"outputs":[]},{"cell_type":"markdown","source":"## Neural Collaborative Filtering\nGMF learn user and item embedding separately. To empower the model it is possible to combine the features of two pathways by concatenating them and passing this concatenation to a Multi-Layer Perceptron (MLP) to learn the interaction between user and item latent features. This model is known as Neural Collaborative Filtering (NCF)\n\nThe input to the model is userID and itemID, which is fed into an embedding layer. Thus, each user and item is given an embedding. Then there are multiple dense layers afterward, followed by a single neuron with a sigmoid activation.\n\nThe output of the sigmoid neuron can be interpreted as the probability the user is likely to interact with an item.\n\nThe model, we are going to implement is the following:\n<center>  <img src=\"https://drive.google.com/uc?export=view&id=1rL_8kkHIhSlQjWr8hNal4Tyog87-2kNP\" width=\"550\" height=\"350\"> </center>\n\nThe user in item vectors are passed to an embedding layer that build a dense or latent vectors for the sparse inputs, from the input layer. The obtained latent vectors are fed into the multi-layer neural architecture, to map the latent vectors to the predicted probability scores. The layers are responsible to find the complex user-item relations from the data.\n\nThe output layer produces the predicted score $y_(ui)$, i.e, how much is the probability that the user u will interact with the item i.\n\nA pointwise loss function is used to minimize the difference between the target value Y(ui) and the corresponding predicted value.\n\nFormally the model we are going to implement is the following:\n\n$$\\mathbf{z_1} = \\phi_1 (\\mathbf{p_u}, \\mathbf{q_i}) = \\begin{bmatrix}\n\\mathbf{p_u} \\\\ \\mathbf{q_i}\n\\end{bmatrix}$$\n\n$$\\phi_L(\\mathbf{z}_{L-1}) = a_L(\\mathbf{W}_L^T\\mathbf{z}_{L-1} + \\mathbf{b}_L)$$\n\n$$ y_{ui} = \\sigma(\\mathbf{h}^T\\phi_L(\\mathbf{z}_{L-1}))$$\n\nwhere $\\mathbf{W}_x, \\mathbf{b}_x, a_x$ denotes the weight matrix, bias vector and activation function for the x-th layer's perceptron\n","metadata":{"id":"FSUXUsUS5OoW"}},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, args, num_users, num_items):\n        super(MLP, self).__init__()\n        self.num_users = num_users\n        self.num_items = num_items\n        self.factor_num = args.factor_num\n        self.layers = args.layers\n\n        self.embedding_user = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num)\n        self.embedding_item = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num)\n\n        self.fc_layers = nn.ModuleList()\n        for idx, (in_size, out_size) in enumerate(zip(self.layers[:-1], self.layers[1:])):\n            self.fc_layers.append(nn.Linear(in_size, out_size))\n\n        self.affine_output = nn.Linear(in_features=self.layers[-1], out_features=1)\n        self.logistic = nn.Sigmoid()\n\n    def forward(self, user_indices, item_indices):\n        user_embedding = self.embedding_user(user_indices)\n        item_embedding = self.embedding_item(item_indices)\n        vector = torch.cat([user_embedding, item_embedding], dim=-1)  # the concat latent vector\n        for idx, _ in enumerate(range(len(self.fc_layers))):\n            vector = self.fc_layers[idx](vector)\n            vector = nn.ReLU()(vector)\n            # vector = nn.BatchNorm1d()(vector)\n            # vector = nn.Dropout(p=0.5)(vector)\n        logits = self.affine_output(vector)\n        rating = self.logistic(logits)\n        return rating.squeeze()\n\n    def init_weight(self):\n        pass","metadata":{"id":"sokr3I_8d5tS","execution":{"iopub.status.busy":"2024-05-02T20:20:32.311903Z","iopub.execute_input":"2024-05-02T20:20:32.312339Z","iopub.status.idle":"2024-05-02T20:20:32.325675Z","shell.execute_reply.started":"2024-05-02T20:20:32.312299Z","shell.execute_reply":"2024-05-02T20:20:32.324312Z"},"trusted":true},"execution_count":391,"outputs":[]},{"cell_type":"code","source":"#collapse-hide\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--seed\",\n\ttype=int,\n\tdefault=42,\n\thelp=\"Seed\")\nparser.add_argument(\"--lr\",\n\ttype=float,\n\tdefault=0.001,\n\thelp=\"learning rate\")\nparser.add_argument(\"--dropout\",\n\ttype=float,\n\tdefault=0.2,\n\thelp=\"dropout rate\")\nparser.add_argument(\"--batch_size\",\n\ttype=int,\n\tdefault=256,\n\thelp=\"batch size for training\")\nparser.add_argument(\"--epochs\",\n\ttype=int,\n\tdefault=30,\n\thelp=\"training epoches\")\nparser.add_argument(\"--top_k\",\n\ttype=int,\n\tdefault=10,\n\thelp=\"compute metrics@top_k\")\nparser.add_argument(\"--factor_num\",\n\ttype=int,\n\tdefault=32,\n\thelp=\"predictive factors numbers in the model\")\nparser.add_argument(\"--layers\",\n    nargs='+',\n    default=[64,32,16,8],\n    help=\"MLP layers. Note that the first layer is the concatenation of user \\\n    and item embeddings. So layers[0]/2 is the embedding size.\")\nparser.add_argument(\"--num_ng\",\n\ttype=int,\n\tdefault=4,\n\thelp=\"Number of negative samples for training set\")\nparser.add_argument(\"--num_ng_test\",\n\ttype=int,\n\tdefault=100,\n\thelp=\"Number of negative samples for test set\")\nparser.add_argument(\"--out\",\n\tdefault=True,\n\thelp=\"save model or not\")","metadata":{"id":"TzFNcyild5y8","outputId":"fe23e849-3223-4ddc-adc8-5d5a38e561b2","execution":{"iopub.status.busy":"2024-05-02T20:20:34.903907Z","iopub.execute_input":"2024-05-02T20:20:34.904639Z","iopub.status.idle":"2024-05-02T20:20:34.920264Z","shell.execute_reply.started":"2024-05-02T20:20:34.904589Z","shell.execute_reply":"2024-05-02T20:20:34.919001Z"},"trusted":true},"execution_count":392,"outputs":[{"execution_count":392,"output_type":"execute_result","data":{"text/plain":"_StoreAction(option_strings=['--out'], dest='out', nargs=None, const=None, default=True, type=None, choices=None, required=False, help='save model or not', metavar=None)"},"metadata":{}}]},{"cell_type":"code","source":"args=parser.parse_args(\"\")\nprint(args)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:25:11.027516Z","iopub.execute_input":"2024-05-02T16:25:11.027911Z","iopub.status.idle":"2024-05-02T16:25:11.033864Z","shell.execute_reply.started":"2024-05-02T16:25:11.027884Z","shell.execute_reply":"2024-05-02T16:25:11.032669Z"},"trusted":true},"execution_count":177,"outputs":[{"name":"stdout","text":"Namespace(seed=42, lr=0.001, dropout=0.2, batch_size=256, epochs=30, top_k=10, factor_num=64, layers=[64, 32, 16, 8], num_ng=4, num_ng_test=100, out=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"#model_GMF = torch.load('/kaggle/input100k/GMF.pt')","metadata":{"id":"YCveUhjFn2aZ","execution":{"iopub.status.busy":"2024-05-02T15:46:13.242676Z","iopub.execute_input":"2024-05-02T15:46:13.243093Z","iopub.status.idle":"2024-05-02T15:46:13.248183Z","shell.execute_reply.started":"2024-05-02T15:46:13.243049Z","shell.execute_reply":"2024-05-02T15:46:13.247031Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"model_GMF","metadata":{"execution":{"iopub.status.busy":"2024-05-02T09:35:11.851249Z","iopub.execute_input":"2024-05-02T09:35:11.851628Z","iopub.status.idle":"2024-05-02T09:35:11.857955Z","shell.execute_reply.started":"2024-05-02T09:35:11.851598Z","shell.execute_reply":"2024-05-02T09:35:11.856995Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"GMF(\n  (embedding_user): Embedding(944, 64)\n  (embedding_item): Embedding(1683, 64)\n  (affine_output): Linear(in_features=64, out_features=1, bias=True)\n  (logistic): Sigmoid()\n)"},"metadata":{}}]},{"cell_type":"code","source":"model_GMF","metadata":{"id":"aqrWhSirBV8C","outputId":"d9273d65-c60e-4fed-f209-5ffdb7ce1dab","execution":{"iopub.status.busy":"2024-05-02T08:49:33.482214Z","iopub.execute_input":"2024-05-02T08:49:33.482488Z","iopub.status.idle":"2024-05-02T08:49:33.490694Z","shell.execute_reply.started":"2024-05-02T08:49:33.482465Z","shell.execute_reply":"2024-05-02T08:49:33.489804Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"GMF(\n  (embedding_user): Embedding(944, 32)\n  (embedding_item): Embedding(1683, 32)\n  (affine_output): Linear(in_features=32, out_features=1, bias=True)\n  (logistic): Sigmoid()\n)"},"metadata":{}}]},{"cell_type":"code","source":"ml_100k = pd.read_csv(\n\tDATA_PATH,\n\tsep=\"\\t\",\n\tnames = ['user_id', 'item_id', 'rating', 'timestamp'],\n\tengine='python')","metadata":{"id":"IqBqcH7l4rwZ","execution":{"iopub.status.busy":"2024-05-02T13:16:48.622539Z","iopub.execute_input":"2024-05-02T13:16:48.622942Z","iopub.status.idle":"2024-05-02T13:16:49.408446Z","shell.execute_reply.started":"2024-05-02T13:16:48.622913Z","shell.execute_reply":"2024-05-02T13:16:49.407586Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"ml_100k.info()","metadata":{"id":"3EOX2ENXuj8_","outputId":"a1ebeea7-d4ea-4401-c1d0-7fd7733f77ab","execution":{"iopub.status.busy":"2024-05-02T13:18:56.096448Z","iopub.execute_input":"2024-05-02T13:18:56.096842Z","iopub.status.idle":"2024-05-02T13:18:56.117413Z","shell.execute_reply.started":"2024-05-02T13:18:56.096812Z","shell.execute_reply":"2024-05-02T13:18:56.116377Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100000 entries, 0 to 99999\nData columns (total 4 columns):\n #   Column     Non-Null Count   Dtype\n---  ------     --------------   -----\n 0   user_id    100000 non-null  int64\n 1   item_id    100000 non-null  int64\n 2   rating     100000 non-null  int64\n 3   timestamp  100000 non-null  int64\ndtypes: int64(4)\nmemory usage: 3.1 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"ml_100k.describe()","metadata":{"id":"LQs3jDWfFFKR","outputId":"ae7913c8-3638-4344-f94e-e40ad76b0ba5","execution":{"iopub.status.busy":"2024-05-02T13:17:45.755564Z","iopub.execute_input":"2024-05-02T13:17:45.755979Z","iopub.status.idle":"2024-05-02T13:17:45.794009Z","shell.execute_reply.started":"2024-05-02T13:17:45.755952Z","shell.execute_reply":"2024-05-02T13:17:45.793024Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            user_id        item_id         rating     timestamp\ncount  100000.00000  100000.000000  100000.000000  1.000000e+05\nmean      462.48475     425.530130       3.529860  8.835289e+08\nstd       266.61442     330.798356       1.125674  5.343856e+06\nmin         1.00000       1.000000       1.000000  8.747247e+08\n25%       254.00000     175.000000       3.000000  8.794487e+08\n50%       447.00000     322.000000       4.000000  8.828269e+08\n75%       682.00000     631.000000       4.000000  8.882600e+08\nmax       943.00000    1682.000000       5.000000  8.932866e+08","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100000.00000</td>\n      <td>100000.000000</td>\n      <td>100000.000000</td>\n      <td>1.000000e+05</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>462.48475</td>\n      <td>425.530130</td>\n      <td>3.529860</td>\n      <td>8.835289e+08</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>266.61442</td>\n      <td>330.798356</td>\n      <td>1.125674</td>\n      <td>5.343856e+06</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>8.747247e+08</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>254.00000</td>\n      <td>175.000000</td>\n      <td>3.000000</td>\n      <td>8.794487e+08</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>447.00000</td>\n      <td>322.000000</td>\n      <td>4.000000</td>\n      <td>8.828269e+08</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>682.00000</td>\n      <td>631.000000</td>\n      <td>4.000000</td>\n      <td>8.882600e+08</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>943.00000</td>\n      <td>1682.000000</td>\n      <td>5.000000</td>\n      <td>8.932866e+08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model_MLP = torch.load('/kaggle/input100k/MLP.pt')","metadata":{"id":"JFgf5vGio5bz","execution":{"iopub.status.busy":"2024-05-02T14:13:00.529482Z","iopub.execute_input":"2024-05-02T14:13:00.530275Z","iopub.status.idle":"2024-05-02T14:13:00.534786Z","shell.execute_reply.started":"2024-05-02T14:13:00.530235Z","shell.execute_reply":"2024-05-02T14:13:00.533589Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model_MLP","metadata":{"id":"oImBUunw-uzo","outputId":"7190b4b9-9d94-44e8-ade6-0e2f41688559","execution":{"iopub.status.busy":"2024-05-02T09:08:19.041456Z","iopub.execute_input":"2024-05-02T09:08:19.042052Z","iopub.status.idle":"2024-05-02T09:08:19.048160Z","shell.execute_reply.started":"2024-05-02T09:08:19.042022Z","shell.execute_reply":"2024-05-02T09:08:19.047152Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"MLP(\n  (embedding_user): Embedding(944, 32)\n  (embedding_item): Embedding(1683, 32)\n  (fc_layers): ModuleList(\n    (0): Linear(in_features=64, out_features=32, bias=True)\n    (1): Linear(in_features=32, out_features=16, bias=True)\n    (2): Linear(in_features=16, out_features=8, bias=True)\n  )\n  (affine_output): Linear(in_features=8, out_features=1, bias=True)\n  (logistic): Sigmoid()\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## LAB CHALLENGE: Neural Matrix Factorization\nSo far we have developed GMF that applies a linear kernel to model the latent feature interactions and MLP that uses a non-linear kernel to learn the interaction function from data.\n\nHow can we fuse GMF and MLP under the NCF framework, so that they can mutually reinforce each other to better model the complex user-item interactions?\n\nA straightforward solution is to let GMF and MLP share the same embedding layer and then combine the outputs of their interaction functions.\n\nTo provide flexibility to the fused model we want to allow GMF and MLP to learn separate embeddings and combine two models by concatenating their last hidden layer.\n\nFormally\n\n$$\\phi^{GMF} = \\mathbf{p_u}^G\\odot \\mathbf{q_i}^G$$\n$$\\phi^{MLP} = a_L(\\mathbf{W}_L^T(a_{L-1}(...a_2 (\\mathbf{W}_2^T \\begin{bmatrix}\n\\mathbf{p_u} \\\\ \\mathbf{q_i}\n\\end{bmatrix} + \\mathbf{b}_2)...)) + \\mathbf{b}_L)$$\n\n$$ y_{ui} = \\sigma(\\mathbf{h}^T \\begin{bmatrix}\n\\ \\phi^{GMF} \\\\ \\phi^{MLP}\n\\end{bmatrix})$$\n\nthat results in the following model architecture\n\n<center>  <img src=\"https://drive.google.com/uc?export=view&id=1gNLUpiQdbDPMdvfZYVs3lcou3cd4Favb\" width=\"550\" height=\"400\"> </center>\n\n\n- TASK 1: implement the model as described\n- TASK 2: compare the performance of such model with the GMS and MLP models using the metrics provided.\n- TASK 3: tune the networks by plotting HR@10 and NDCG@10 with respect to the number of predictive factors [8, 16, 32, 64] for all the 3 algorithms\n","metadata":{"id":"nGl8O6kYqnvq"}},{"cell_type":"code","source":"#TASK 1\n#this the one this is using\nclass NeuMF(nn.Module):\n    def __init__(self, args, num_users, num_items):\n        super(NeuMF, self).__init__()\n        self.num_users = num_users\n        self.num_items = num_items\n        self.factor_num_mf = args.factor_num\n        self.factor_num_mlp = args.layers[0] // 2\n        self.layers = args.layers\n        self.dropout = args.dropout\n\n        # GMF part\n        self.embedding_user_GMF = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num_mf)\n        self.embedding_item_GMF = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num_mf)\n\n        # MLP part\n        self.embedding_user_MLP = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num_mlp)\n        self.embedding_item_MLP = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num_mlp)\n\n        self.fc_layers = nn.ModuleList()\n        for idx, (in_size, out_size) in enumerate(zip(self.layers[:-1], self.layers[1:])):\n            self.fc_layers.append(nn.Linear(in_size, out_size))\n\n        # Output layer\n        self.affine_output = nn.Linear(in_features=self.layers[-1] + self.factor_num_mf, out_features=1)\n        self.logistic = nn.Sigmoid()\n\n    def forward(self, user_indices, item_indices):\n        # GMF\n        user_embedding_GMF = self.embedding_user_GMF(user_indices)\n        item_embedding_GMF = self.embedding_item_GMF(item_indices)\n        vector_GMF = torch.mul(user_embedding_GMF, item_embedding_GMF)\n\n        # MLP\n        user_embedding_MLP = self.embedding_user_MLP(user_indices)\n        item_embedding_MLP = self.embedding_item_MLP(item_indices)\n        vector_MLP = torch.cat([user_embedding_MLP, item_embedding_MLP], dim=-1)  # the concat latent vector\n        for idx, _ in enumerate(range(len(self.fc_layers))):\n            vector_MLP = self.fc_layers[idx](vector_MLP)\n            vector_MLP = nn.ReLU()(vector_MLP)\n            vector_MLP = nn.Dropout(p=self.dropout)(vector_MLP)\n\n        # Concatenate GMF and MLP vectors\n        vector = torch.cat([vector_GMF, vector_MLP], dim=-1)\n\n        # Output layer\n        logits = self.affine_output(vector)\n        rating = self.logistic(logits)\n        return rating.squeeze()\n\n    def init_weight(self):\n        pass\n","metadata":{"id":"3Anh055LIljk","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-02T20:20:40.544878Z","iopub.execute_input":"2024-05-02T20:20:40.545708Z","iopub.status.idle":"2024-05-02T20:20:40.562187Z","shell.execute_reply.started":"2024-05-02T20:20:40.545667Z","shell.execute_reply":"2024-05-02T20:20:40.561041Z"},"trusted":true},"execution_count":393,"outputs":[]},{"cell_type":"code","source":"def TrainGMF(factor,epo,lay):\n    # set device and parameters\n    args = parser.parse_args(\"\")\n    args.layers=lay\n    args.factor_num=factor\n    args.epochs=epo\n    #args.layers=lay\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\n    list_HR=[]\n    list_NDCG=[]\n    # load data\n    ml_100k = pd.read_csv(\n        DATA_PATH,\n        sep=\"\\t\",\n        names = ['user_id', 'item_id', 'rating', 'timestamp'],\n        engine='python')\n\n    # set the num_users, items\n    num_users = ml_100k['user_id'].nunique()+1\n    num_items = ml_100k['item_id'].nunique()+1\n\n    # construct the train and test datasets\n    data = NCF_Data(args, ml_100k)\n    train_loader = data.get_train_instance()\n    test_loader = data.get_test_instance()\n\n    # set model and loss, optimizer\n    model = GMF(args, num_users, num_items)\n    model = model.to(device)\n    loss_function = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n\n    # train, evaluation\n    best_hr = 0\n    for epoch in range(1, args.epochs+1):\n        model.train() # Enable dropout (if have).\n        start_time = time.time()\n\n        for user, item, label in train_loader:\n            user = user.to(device)\n            item = item.to(device)\n            label = label.to(device)\n\n            optimizer.zero_grad()\n            prediction = model(user, item)\n            loss = loss_function(prediction, label)\n            loss.backward()\n            optimizer.step()\n            #writer.add_scalar('loss/Train_loss', loss.item(), epoch)\n\n        model.eval()\n        HR, NDCG = metrics(model, test_loader, args.top_k, device)\n        #writer.add_scalar('Perfomance/HR@10', HR, epoch)\n        #writer.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n\n        elapsed_time = time.time() - start_time\n        #print(\"GMF=================================================================GMF\")\n        #print(\"Epoch {:03d}\".format(epoch) + \" time to train: \" +\n            #time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n        #print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n        list_HR.append(np.mean(HR))\n        list_NDCG.append(np.mean(NDCG))\n        #print(\"this is HR****************************\",list_HR)\n        #print(\"this is NDCG****************************\",list_NDCG)\n\n        if HR > best_hr:\n            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n            if args.out:\n                if not os.path.exists(MODEL_PATH):\n                    os.mkdir(MODEL_PATH)\n                torch.save(model,\n                    '{}{}.pt'.format(MODEL_PATH, model.__class__.__name__))\n    return list_HR,list_NDCG\n\n     ","metadata":{"execution":{"iopub.status.busy":"2024-05-02T21:18:28.472923Z","iopub.execute_input":"2024-05-02T21:18:28.473694Z","iopub.status.idle":"2024-05-02T21:18:28.491912Z","shell.execute_reply.started":"2024-05-02T21:18:28.473648Z","shell.execute_reply":"2024-05-02T21:18:28.490526Z"},"trusted":true},"execution_count":422,"outputs":[]},{"cell_type":"code","source":"def TrainMLP(factor,epo,lay):\n    # set device and parameters\n    args = parser.parse_args(\"\")\n    args.layers=lay\n    args.factor_num=factor\n    args.epochs=epo\n    #args.layers=lay\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\n    list_HR=[]\n    list_NDCG=[]\n    # load data\n    ml_100k = pd.read_csv(\n        DATA_PATH,\n        sep=\"\\t\",\n        names = ['user_id', 'item_id', 'rating', 'timestamp'],\n        engine='python')\n\n    # set the num_users, items\n    num_users = ml_100k['user_id'].nunique()+1\n    num_items = ml_100k['item_id'].nunique()+1\n\n    # construct the train and test datasets\n    data = NCF_Data(args, ml_100k)\n    train_loader = data.get_train_instance()\n    test_loader = data.get_test_instance()\n\n    # set model and loss, optimizer\n    model = MLP(args, num_users, num_items)\n    model = model.to(device)\n    loss_function = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n\n    # train, evaluation\n    best_hr = 0\n    for epoch in range(1, args.epochs+1):\n        model.train() # Enable dropout (if have).\n        start_time = time.time()\n\n        for user, item, label in train_loader:\n            user = user.to(device)\n            item = item.to(device)\n            label = label.to(device)\n\n            optimizer.zero_grad()\n            prediction = model(user, item)\n            loss = loss_function(prediction, label)\n            loss.backward()\n            optimizer.step()\n            #writer.add_scalar('loss/Train_loss', loss.item(), epoch)\n\n        model.eval()\n        HR, NDCG = metrics(model, test_loader, args.top_k, device)\n        #writer.add_scalar('Perfomance/HR@10', HR, epoch)\n        #writer.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n\n        elapsed_time = time.time() - start_time\n        #print(\"MLP=================================================================MLP\")\n       # print(\"Epoch {:03d}\".format(epoch) + \" time to train: \" +\n          #  time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n        #print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n        list_HR.append(np.mean(HR))\n        list_NDCG.append(np.mean(NDCG))\n        #print(\"this is HR****************************\",list_HR)\n        #print(\"this is NDCG****************************\",list_NDCG)\n\n        if HR > best_hr:\n            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n            if args.out:\n                if not os.path.exists(MODEL_PATH):\n                    os.mkdir(MODEL_PATH)\n                torch.save(model,\n                    '{}{}.pt'.format(MODEL_PATH, model.__class__.__name__))\n    return list_HR,list_NDCG","metadata":{"execution":{"iopub.status.busy":"2024-05-02T21:18:32.518270Z","iopub.execute_input":"2024-05-02T21:18:32.519295Z","iopub.status.idle":"2024-05-02T21:18:32.534644Z","shell.execute_reply.started":"2024-05-02T21:18:32.519247Z","shell.execute_reply":"2024-05-02T21:18:32.533525Z"},"trusted":true},"execution_count":423,"outputs":[]},{"cell_type":"code","source":"def TrainNeuMF(factor,epo,lay):\n    # set device and parameters\n    args = parser.parse_args(\"\")\n    args.layers=lay\n    args.factor_num=factor\n    args.epochs=epo\n    #args.layers=lay\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\n    list_HR=[]\n    list_NDCG=[]\n    # load data\n    ml_100k = pd.read_csv(\n        DATA_PATH,\n        sep=\"\\t\",\n        names = ['user_id', 'item_id', 'rating', 'timestamp'],\n        engine='python')\n\n    # set the num_users, items\n    num_users = ml_100k['user_id'].nunique()+1\n    num_items = ml_100k['item_id'].nunique()+1\n\n    # construct the train and test datasets\n    data = NCF_Data(args, ml_100k)\n    train_loader = data.get_train_instance()\n    test_loader = data.get_test_instance()\n\n    # set model and loss, optimizer\n    model = NeuMF(args, num_users, num_items)\n    model = model.to(device)\n    loss_function = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n\n    # train, evaluation\n    best_hr = 0\n    for epoch in range(1, args.epochs+1):\n        model.train() # Enable dropout (if have).\n        start_time = time.time()\n\n        for user, item, label in train_loader:\n            user = user.to(device)\n            item = item.to(device)\n            label = label.to(device)\n\n            optimizer.zero_grad()\n            prediction = model(user, item)\n            loss = loss_function(prediction, label)\n            loss.backward()\n            optimizer.step()\n            #writer.add_scalar('loss/Train_loss', loss.item(), epoch)\n\n        model.eval()\n        HR, NDCG = metrics(model, test_loader, args.top_k, device)\n        #writer.add_scalar('Perfomance/HR@10', HR, epoch)\n        #writer.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n\n        elapsed_time = time.time() - start_time\n        #print(\"NEUMF=================================================================NeuMF\")\n        #print(\"Epoch {:03d}\".format(epoch) + \" time to train: \" +\n        #    time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n        #print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n        list_HR.append(np.mean(HR))\n        list_NDCG.append(np.mean(NDCG))\n        #print(\"this is HR****************************\",list_HR)\n        #print(\"this is NDCG****************************\",list_NDCG)\n\n        if HR > best_hr:\n            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n            if args.out:\n                if not os.path.exists(MODEL_PATH):\n                    os.mkdir(MODEL_PATH)\n                torch.save(model,\n                    '{}{}.pt'.format(MODEL_PATH, model.__class__.__name__))\n    return list_HR,list_NDCG\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T21:18:35.086348Z","iopub.execute_input":"2024-05-02T21:18:35.086777Z","iopub.status.idle":"2024-05-02T21:18:35.103329Z","shell.execute_reply.started":"2024-05-02T21:18:35.086744Z","shell.execute_reply":"2024-05-02T21:18:35.101957Z"},"trusted":true},"execution_count":424,"outputs":[]},{"cell_type":"code","source":"print(args)\nfactors_list = [8, 16, 32, 64]\nfactors_scores_hr_GMF={}\nfactors_scores_ndcg_gmf={}\n\nfactors_scores_hr_NeuM={}\nfactors_scores_ndcg_NeurMF={}\n\n\nepo=30\n#lay=[128,64,32,16]\nlay=[64,32,16,8]\nprint(args)\nfor factor in factors_list:\n    factors_scores_hr_GMF[factor],factors_scores_ndcg_gmf[factor]=TrainGMF(factor,epo=epo,lay=lay)\nfor factor in factors_list:\n    factors_scores_hr_NeuM[factor],factors_scores_ndcg_NeurMF[factor]=TrainNeuMF(factor,epo=epo,lay=lay)\n    \n\n    \n\nprint(factors_scores_hr_GMF)\nfactors_scores_hr_GMF=factors_scores_hr_GMF\n\nprint(factors_scores_ndcg_gmf)\nfactors_scores_ndcg_gmf=factors_scores_ndcg_gmf\n\n\n\n\n\nprint(factors_scores_hr_NeuM)\nfactors_scores_hr_NeuM=factors_scores_hr_NeuM\n\nprint(factors_scores_ndcg_NeurMF)\nfactors_scores_ndcg_NeurMF=factors_scores_ndcg_NeurMF\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nprint(args)\nfactors_scores_hr_MLP={}\nfactors_scores_ndcg_MLP={}\n\n\n\n\nepo=30\nprint(args)\n\n\n\n\n#trainin MLP for factor 64   \nfactor=64\nlayers=[128,64,32,16]\nfactors_scores_hr_MLP_64,factors_scores_ndcg_MLP_64=TrainMLP(factor=64,epo=epo,lay=layers)\n\n\n\nprint(factors_scores_hr_MLP_64)\nfactors_scores_hr_MLP_64=factors_scores_hr_MLP_64\n\nprint(factors_scores_ndcg_MLP_64)\nfactors_scores_ndcg_MLP_64=factors_scores_ndcg_MLP_64\n\nprint(\"-----------------------------64 finish\")\n\n\n#trainin MLP for factor 32   \nfactor=32\nlayers=[64,32,16,8]\nfactors_scores_hr_MLP_32,factors_scores_ndcg_MLP_32=TrainMLP(factor=factor,epo=epo,lay=layers)\n\n\n\nprint(factors_scores_hr_MLP_32)\nfactors_scores_hr_MLP_32\n\nprint(factors_scores_ndcg_MLP_32)\nfactors_scores_ndcg_MLP_32\nprint(\"-----------------------------32 finish\")\n\n\n#trainin MLP for factor 16  \nfactor=16\nlayers=[32,16,8,4]\nfactors_scores_hr_MLP_16,factors_scores_ndcg_MLP_16=TrainMLP(factor=factor,epo=epo,lay=layers)\n\n\n\nprint(factors_scores_hr_MLP_16)\nfactors_scores_hr_MLP_16\n\nprint(factors_scores_ndcg_MLP_16)\nfactors_scores_ndcg_MLP_16\n\nprint(\"-----------------------------16 finish\")\n\n#trainin MLP for factor 8   \nfactor=8\nlayers=[16,8,4,2]\nfactors_scores_hr_MLP_8,factors_scores_ndcg_MLP_8=TrainMLP(factor=factor,epo=epo,lay=layers)\n\n\n\nprint(factors_scores_hr_MLP_8)\nfactors_scores_hr_MLP_8\n\nprint(factors_scores_ndcg_MLP_8)\nfactors_scores_ndcg_MLP_8\n\nprint(\"-----------------------------8 finish\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T21:18:54.876714Z","iopub.execute_input":"2024-05-02T21:18:54.877656Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Namespace(seed=42, lr=0.001, dropout=0.2, batch_size=256, epochs=30, top_k=10, factor_num=64, layers=[64, 32, 16, 8], num_ng=4, num_ng_test=100, out=True)\nNamespace(seed=42, lr=0.001, dropout=0.2, batch_size=256, epochs=30, top_k=10, factor_num=64, layers=[64, 32, 16, 8], num_ng=4, num_ng_test=100, out=True)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/3834424632.py:52: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n/tmp/ipykernel_34/3834424632.py:58: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n","output_type":"stream"},{"name":"stdout","text":"[0.41145281018027574, 0.40402969247083775, 0.41251325556733826, 0.44220572640509015, 0.48462354188759277, 0.513255567338282, 0.5259809119830329, 0.5408271474019088, 0.5493107104984093, 0.5588547189819725, 0.559915164369035, 0.574761399787911, 0.5768822905620361, 0.574761399787911, 0.5927889713679746, 0.5726405090137858, 0.574761399787911, 0.5705196182396607, 0.5694591728525981, 0.584305408271474, 0.5758218451749735, 0.5832449628844114, 0.5705196182396607, 0.5874867444326617, 0.5779427359490986]\n[0.2220372101853989, 0.22261261643992789, 0.23069743936685078, 0.24820094019782732, 0.2712700547072959, 0.29046139354709, 0.29380247463963927, 0.30444654164063795, 0.3081121486016476, 0.30987139876688313, 0.31162689850435904, 0.32765917536510525, 0.3206345718065638, 0.3207106621898653, 0.32857441077113836, 0.32245346609518105, 0.3190010780036417, 0.3282532861053065, 0.32430202810369213, 0.32589104142083325, 0.3227040823145546, 0.3238797276428864, 0.3217652476245553, 0.3298249067534794, 0.3241596324722889]\n-----------------------------64 finish\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/3834424632.py:52: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n/tmp/ipykernel_34/3834424632.py:58: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n","output_type":"stream"},{"name":"stdout","text":"[0.4146341463414634, 0.4135737009544008, 0.41993637327677624, 0.42311770943796395, 0.4188759278897137, 0.42629904559915166, 0.4411452810180276, 0.45068928950159065, 0.4687168610816543, 0.48568398727465534, 0.5026511134676565, 0.5079533404029692, 0.5302226935312832, 0.5334040296924708, 0.5471898197242842, 0.5482502651113468, 0.5588547189819725, 0.5694591728525981, 0.5567338282078473, 0.5694591728525981, 0.559915164369035, 0.5556733828207847, 0.5683987274655355, 0.5620360551431601, 0.5673382820784729]\n[0.22115825616165358, 0.22035835581201244, 0.22145148521258645, 0.22179852663563465, 0.22351333843059884, 0.23066640536541888, 0.24057459406301188, 0.25080730662865475, 0.2584342490572622, 0.26794534049943813, 0.2788589238251503, 0.28579098937556957, 0.29040854648243675, 0.2950550885588914, 0.2993907604793657, 0.3044291064523463, 0.3071699843595565, 0.3134177960911778, 0.30883685330126937, 0.31001415514260966, 0.3049717815651543, 0.3046253348478195, 0.30681194019200286, 0.3071889814580798, 0.31116485384964826]\n-----------------------------32 finish\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/3834424632.py:52: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n/tmp/ipykernel_34/3834424632.py:58: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n","output_type":"stream"},{"name":"stdout","text":"[0.3934252386002121, 0.3944856839872747, 0.39660657476139977, 0.4029692470837752, 0.4019088016967126, 0.4146341463414634, 0.4209968186638388, 0.42735949098621423, 0.4443266171792153, 0.4559915164369035, 0.4676564156945917, 0.47932131495228, 0.4941675503711559, 0.49628844114528103, 0.49522799575821846, 0.5005302226935313, 0.5047720042417816, 0.5058324496288441, 0.503711558854719, 0.5143160127253447, 0.5153764581124072, 0.5227995758218452, 0.5344644750795334, 0.5249204665959704, 0.5174973488865323]\n[0.20656456506218548, 0.21640316310978241, 0.2176345619473022, 0.2194946513017961, 0.21734920862122417, 0.2255399918255817, 0.22895012055118502, 0.23592845228752438, 0.24619346735068995, 0.2562690784817112, 0.26176341083947596, 0.2682525505512554, 0.2738635287960232, 0.27587870806670134, 0.2804584529163429, 0.2805590346009433, 0.2807048688791558, 0.2826537627480745, 0.28329417890946024, 0.28570055413550177, 0.2838489564980512, 0.288490650925261, 0.29132153819001316, 0.2894347315539654, 0.28620344858474256]\n-----------------------------16 finish\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/3834424632.py:52: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n/tmp/ipykernel_34/3834424632.py:58: DeprecationWarning: Sampling from a set deprecated\nsince Python 3.9 and will be removed in a subsequent version.\n  train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt \n\nN = 4\nind = np.arange(N) \nwidth = 0.2\n#for val in factors_scores_hr_GMF:\n    \n\nxvals = [] \nfor val in factors_scores_hr_GMF:\n    xvals.append(max(factors_scores_hr_GMF[val]))\nprint(xvals)\n    \nbar1 = plt.bar(ind, xvals, width, color='r') \n\nyvals = [] \nyvals = [max(factors_scores_hr_MLP_8),max(factors_scores_hr_MLP_16),max(factors_scores_hr_MLP_32),max(factors_scores_hr_MLP_64)] \nprint(yvals)\nbar2 = plt.bar(ind+width, yvals, width, color='g') \n\nzvals = []\nfor val in factors_scores_hr_NeuM:\n    zvals.append(max(factors_scores_hr_NeuM[val]))\nprint(zvals)\nbar3 = plt.bar(ind+width*2, zvals, width, color='b') \n\nplt.xlabel(\"Factors\") \nplt.ylabel('H@10') \nplt.title(\"Mouvilens\") \n\nplt.xticks(ind+width*1.5, ['8', '16', '32', '64'])\nplt.legend((bar1, bar2, bar3), ('GMF', 'MLF', 'NeuMF')) \nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T21:10:10.294381Z","iopub.execute_input":"2024-05-02T21:10:10.294856Z","iopub.status.idle":"2024-05-02T21:10:10.567368Z","shell.execute_reply.started":"2024-05-02T21:10:10.294816Z","shell.execute_reply":"2024-05-02T21:10:10.566265Z"},"trusted":true},"execution_count":413,"outputs":[{"name":"stdout","text":"[0.4019088016967126, 0.3605514316012725, 0.4093319194061506, 0.3997879109225875]\n[1.0, 0.41251325556733826, 0.5100742311770944, 0.5355249204665959]\n[0.41675503711558853, 0.4135737009544008, 0.44750795334040294, 0.41145281018027574]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt \n\nN = 4\nind = np.arange(N) \nwidth = 0.2\n#for val in factors_scores_hr_GMF:\n    \n\nxvals = [] \nfor val in factors_scores_hr_GMF:\n    xvals.append(max(factors_scores_ndcg_gmf[val]))\nprint(xvals)\n    \nbar1 = plt.bar(ind, xvals, width, color='r') \n#\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nyvals = [max(factors_scores_ndcg_MLP_8),max(factors_scores_ndcg_MLP_16),max(factors_scores_ndcg_MLP_32),max(factors_scores_ndcg_MLP_64)] \nprint(yvals)\nbar2 = plt.bar(ind+width, yvals, width, color='g') \n#########################\"\"\nzvals = []\nfor val in factors_scores_hr_NeuM:\n    zvals.append(max(factors_scores_ndcg_NeurMF[val]))\nprint(zvals)\nbar3 = plt.bar(ind+width*2, zvals, width, color='b') \n\nplt.xlabel(\"Factors\") \nplt.ylabel('NDCG@10') \nplt.title(\"Mouvilens\") \n\nplt.xticks(ind+width*1.5, ['8', '16', '32', '64'])\nplt.legend((bar1, bar2, bar3), ('GMF', 'MLF', 'NeuMF')) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-02T21:16:14.218153Z","iopub.execute_input":"2024-05-02T21:16:14.218581Z","iopub.status.idle":"2024-05-02T21:16:14.580217Z","shell.execute_reply.started":"2024-05-02T21:16:14.218546Z","shell.execute_reply":"2024-05-02T21:16:14.579195Z"},"trusted":true},"execution_count":419,"outputs":[{"name":"stdout","text":"[0.22518724133337265, 0.18775320250471977, 0.22091959533062341, 0.22279810037161626]\n[0.36360394075110863, 0.2164143930609374, 0.2211787850568238, 0.2219475338552444]\n[0.21644221093493216, 0.22654089692539767, 0.2472716425375847, 0.20661255938320944]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"dic={}\nfor i in [1,2,3,4]:\n    dic[i]=i\nprint(dic)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T17:28:04.807098Z","iopub.execute_input":"2024-05-02T17:28:04.807485Z","iopub.status.idle":"2024-05-02T17:28:04.813371Z","shell.execute_reply.started":"2024-05-02T17:28:04.807456Z","shell.execute_reply":"2024-05-02T17:28:04.812139Z"},"trusted":true},"execution_count":225,"outputs":[{"name":"stdout","text":"{1: 1, 2: 2, 3: 3, 4: 4}\n","output_type":"stream"}]},{"cell_type":"code","source":"\n###############64\n\nprint(factors_scores_hr_MLP_64)\nprint(factors_scores_ndcg_MLP_64)\n\n######## \"32\"\nprint(factors_scores_hr_MLP_32)\n\nprint(factors_scores_ndcg_MLP_32)\n\n\n#trainin MLP for factor 16  \n\n\nprint(factors_scores_hr_MLP_16)\n\nprint(factors_scores_ndcg_MLP_16)\n\n\n#trainin MLP for factor 8   \nprint(factors_scores_hr_MLP_8)\n\nprint(factors_scores_ndcg_MLP_8)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T21:15:54.357816Z","iopub.execute_input":"2024-05-02T21:15:54.358100Z","iopub.status.idle":"2024-05-02T21:15:54.368162Z","shell.execute_reply.started":"2024-05-02T21:15:54.358075Z","shell.execute_reply":"2024-05-02T21:15:54.367177Z"},"trusted":true},"execution_count":418,"outputs":[{"name":"stdout","text":"[0.39236479321314954, 0.40084835630965004]\n[0.21801413906772873, 0.2219475338552444]\n[0.39236479321314954, 0.4050901378579003]\n[0.216655979457407, 0.2211787850568238]\n[0.3806998939554613, 0.39236479321314954]\n[0.20530630723214438, 0.2164143930609374]\n[1.0, 0.9915164369034994]\n[0.3568225817852297, 0.36360394075110863]\n","output_type":"stream"}]}]}